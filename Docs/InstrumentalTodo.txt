- Get a simple resizable panel working.
- Create a keyvalue/pair binding list for mapping schema controls to runtime controls.
	- Upon loading a schema (editor or runtime), populate the runtime control list with proper data from the schema.
	
- Fillet panel struggles with no radius segments, it's a triangle index bug of some kind.
- Depth, and extrude handles. Figure out how to change mode of fillet panel to allow extrude
- use RED chan as a color palette inspiration
- Color picker for panel background and outlines
- outline and extrude fails if you don't also do back face.
- Add ability to move the work table height.

- Square panel can use leap outline graphic for outlines
	(there doesn't seem to be a non graphic renderer equivalent though - make one of our own?)
- Figure out how to support multiple colliders on a placeholder object. Currently they cause the space switching to break.
- Ignore collisions between work table and panel to prevent bouncing and popping

Design for color dropper and all other tools:
- InventoryMarkerClass
	- Lets you store controls as well as tools.
- Goes in wrist-mounted anchor slots
- handheld tools can have a menu pulled out of them keiichi slider style
	- In fact, let's use that for the tools menu too.
	- Oh maybe the tools menu can be a rotating thing - like a store jewelry display that spins in place with multiple faces. This would let us stick it to the control palette
	
- Study '3d text' from 98 to early 00's to see how they kept things readable even with extrusions. Might not be too helpful though because all examples from then were fixed-perspective, whereas VR is continuously variable perspective. (One advancement we've made recently in this area is the skate-frame extrude. Extrude upwards, inset the border faces w/o profile change, then extrude those inset faces outwards). It looks like the most important thing for readability is the strength of the silhouette - this gets muddied if the extruded section seamlessly blends into the face section. We can still have depth information here though - make the extruded section a different 'outline' color but it can have a depth-based gradient to it.
	
Pull-out heirarchy:
- Main
	-Panel (This gets stretched)
	-Slider
		-Ball Object
	-Name (show when hovering or looking)
	
	Slider will need some kind of return to center, as well as 'lock to edges' behavior. Perhaps we can do this by directly setting the slider values?
	
- graphic group index and connected renderer appear to be getting corrupted in HandleRuntimeAddRemove() ?
	- Looks like HandleRuntimeAddRemove is getting run twice?
	- (because detaching and attaching operations get bucketed, it looks like detach is getting called after attach. This might be a bug worthy of reporting. A workaround is to distribute these operations across frames)
	
- Graphic group switching runs into issues if you go quickly from palette to panel, works if you slowly go through each zone

- placement controls need to stick to UI panels (Either go kinematic or do force trickery) after they've been placed
	- make it so that you can throw controls onto UI panels. This is dumb but it should be supported


https://github.com/sigtrapgames/SmartData use this for letting users do data connections?
In the intervening years since starting this project, I've learned that React has a nice pseudo-immediate mode system that people really like. Look into providing that here.

Min and max dimensions:
max: x: 0.9, y: 0.6
min: x: 0.09, y: 0.09

Floating object values:
Mass: 1
drag: 8
Angular Drag: 16

-----------------------------------
Button edgeloop:
corner segment is cornerVertCount

0-cornerVertCount: upper left
cornerVertCount-widthCount: upper
widthCount-widthCount+cornerVertCount: upperRight

ok looks like I made a silly mistake - the face of the button is at 0 depth, and the back of the button gets pushed into the negative range. It might not be _that_ silly, there's possible logic to it, such as being able to check if the finger is touching by looking to see if the value is negative, but I think I want to fix that now.

New notes: It looks like I had not finished getting the button model rendering properly, and the legacy buttons were thrown together quickly to solve this.

-----------------------------------
Graphics stuff:
I need to figure out the best way to handle vertex colors and coloration. I want to be able to quickly change colors of certain elements every frame (such as button faces), but doing that per-vertex might be a bad idea. I was thinking we could possibly put the shading value into the vertex colors, and then use a palette system for coloring things dynamically like the hover and touch.

It does look like I can use a similar palette system to the one I'm familiar with. There doesn't seem to be anything in the schema right now for color definitions, so I've got a blank slate to play with there. Ugh the theming is a lot to think about and I kinda don't wanna lol I need to start moving faster too. Hmm. It does look like on the fillet panel at least, we generate the vcolors on generate mesh, and don't modify them during setvertices

Let's provide base colors in the vertex colors. We can have shader common values for:
- Touch Start
- Touch complete
- Hover (far - interaction point is outside of the bounds but nearby)
- Hover (near - interaction point is inside of the bounds)
- Press
- Grasp

Global shader values for:
- interaction positions (left/right)

Material property block data for:
- Touch Amount
- IsPressing
- IsGrasping

- Also the ability to do cubemaps for shiny stuff

-----------------------------------
Working on the finger glow stuff and have run into a bit of a problem: I have the feedback hands providing a position to the gloabl shader vectors, but have noticed a problem: they appear to be in the wrong place, very far away. Not sure what's up with that. Hmm. My code does try to do some funny stuff, like average the positions together. Oh I think I know what's up. Parentheses problem, bad math.

Yep fixed that. I have a new problem now: it looks like my throw values go in the opposite value: 1 being unpressed and 0 being pressed. Need to see if that's intentional but it would certainly be screwing with things.

moving on to detectors:
looks like the palm direction is wrong -0 it's doing forward when we really want to do up. Flipping might need to get taken into account, not sure. Also the dot product is not working the way I expected.

Doing some stuff on the virtual joystick interaction. Uh that was cool I guess lol forgot to take notes.

Back to working on triggers though and it looks like I might want to refactor some stuff - palmdirectiontrigger looks like it's going to have some stuff in common with finger extension trigger, so perhaps I can use inheritance there to avoid code duplication yeye

Alright looking at triggers again: I want to get around to adding the continuous feedback variable I'd been thinking of. One issue though: I was only thinking distance to activation. There are other cases we could consider:

- distance to activation
- intensity of current activation
- distance to deactivation

hmm. Idon't think intensity of current activation is worth it. If we drop it then we can have the continuous value represent 'distance to activation' and 'distance to deactivation' with a single variable that changes meaning depending on the current state.

------------------------------------
Solving the 'tightly packed gizmos' issue:
perhaps we can have a single ball-shaped gizmo that expands when hovered near, into a radial segment of other balls. The other balls can show axial constraints and names as you get closer to them. (Maybe we can do this craigslist-maps style, where the number of gizmos underneath can be a number inside of a ball)